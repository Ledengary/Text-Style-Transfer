{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formal_male_data = []\n",
    "formal_female_data = []\n",
    "informal_male_data = []\n",
    "informal_female_data = []\n",
    "\n",
    "input_path_formal_male = 'Gender tagged corpus English/male/'\n",
    "input_path_formal_female = 'Gender tagged corpus English/female/'\n",
    "\n",
    "# input_path_formal_male = 'Gender tagged corpus English/male/'\n",
    "# input_path_formal_female = 'Gender tagged corpus English/female/'\n",
    "\n",
    "for fileName in listdir(input_path_formal_male)[:50000]:\n",
    "    file = open(input_path_formal_male + fileName, 'r', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    formal_male_data.append(text)\n",
    "    file.close()\n",
    "    \n",
    "for fileName in listdir(input_path_formal_female)[:50000]:\n",
    "    file = open(input_path_formal_female + fileName, 'r', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    formal_female_data.append(text)\n",
    "    file.close()\n",
    "    \n",
    "# for fileName in listdir(input_path_informal_male):\n",
    "#     file = open(input_path_informal_male + fileName, 'r', encoding='utf-8')\n",
    "#     text = file.read()\n",
    "#     informal_male_data.append(text)\n",
    "#     file.close()\n",
    "    \n",
    "# for fileName in listdir(input_path_informal_female):\n",
    "#     file = open(input_path_informal_female + fileName, 'r', encoding='utf-8')\n",
    "#     text = file.read()\n",
    "#     informal_female_data.append(text)\n",
    "#     file.close()\n",
    "\n",
    "# all_data = informal_male_data + informal_female_data + formal_male_data + formal_female_data\n",
    "# all_labels = [1] * (len(informal_male_data) + len(informal_female_data)) + [0] * (len(formal_male_data) + len(formal_female_data))\n",
    "all_data = formal_male_data + formal_female_data\n",
    "all_labels = [1] * len(formal_male_data) + [0] * len(formal_female_data)\n",
    "zipped_list = list(zip(all_data, all_labels))\n",
    "random.shuffle(zipped_list)\n",
    "all_data, all_labels = zip(*zipped_list)\n",
    "all_data = list(all_data)\n",
    "all_labels = list(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_labels, test_labels = train_test_split(all_data, all_labels, test_size=0.2, shuffle=True)\n",
    "print(len(train_text))\n",
    "print(len(train_labels))\n",
    "print(len(test_text))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original: ', train_text[0], train_labels[0])\n",
    "print(\"len(Original) = \", len(train_text[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(train_text[0]))\n",
    "print(\"len(Tokenized) = \", len(tokenizer.tokenize(train_text[0])))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text[0])))\n",
    "print(\"len(Token IDs) = \", len(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_text[0]))))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_id(tokenizer, text_list):\n",
    "    \"\"\"\n",
    "    It is a function to transform text to id.\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    \"\"\"\n",
    "    ids_list = []\n",
    "    \n",
    "    for item in text_list:\n",
    "        # Sentence to id and add [CLS] and [SEP]\n",
    "        encoded_item = tokenizer.encode(item, add_special_tokens=True)\n",
    "        ids_list.append(encoded_item)\n",
    "    \n",
    "    return ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_ids = text_to_id(tokenizer, train_text)\n",
    "test_text_ids = text_to_id(tokenizer, test_text)\n",
    "\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: {}\\n'.format(train_text[0]))\n",
    "print('Token IDs: {}\\n'.format(train_text_ids[0]))\n",
    "print(\"len(train_text_ids) = {}\\n\".format(len(train_text_ids)))\n",
    "print(\"len(test_text_ids) = {}\".format(len(test_text_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: max sentence length: ', max([len(sen) for sen in train_text_ids]))\n",
    "print('Train: Min sentence length: ', min([len(sen) for sen in train_text_ids]))\n",
    "print('Test: max sentence length: ', max([len(sen) for sen in test_text_ids]))\n",
    "print('Test: Min sentence length: ', min([len(sen) for sen in test_text_ids]))\n",
    "\n",
    "# for aaa in train_text_ids:\n",
    "#     if len(aaa) == 1558:\n",
    "#         print(aaa)\n",
    "#         break\n",
    "# print('\\n' * 20)\n",
    "# for each in test_text_ids:\n",
    "#     if len(each) == 1558:\n",
    "#         print(each)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_truncating(input_ids_list, max_length):\n",
    "    processed_input_ids_list = []\n",
    "    for item in input_ids_list:\n",
    "        seq_list = []\n",
    "        if len(item) < max_length:\n",
    "            seq_list = [0] * (max_length - len(item))\n",
    "            item = item + seq_list\n",
    "        \n",
    "        elif len(item) >= max_length:\n",
    "            item = item[:max_length]\n",
    "            \n",
    "        processed_input_ids_list.append(item)\n",
    "    return processed_input_ids_list\n",
    "\n",
    "def get_attention_masks(pad_input_ids_list):\n",
    "    \"\"\"\n",
    "    It is a function to get attention masks:\n",
    "    \n",
    "    - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    \"\"\"\n",
    "    attention_masks_list = []\n",
    "    \n",
    "    for item in pad_input_ids_list:\n",
    "        \n",
    "        mask_list = []\n",
    "        for subitem in item:\n",
    "            if subitem > 0:\n",
    "                mask_list.append(1)\n",
    "            else:\n",
    "                mask_list.append(0)\n",
    "        attention_masks_list.append(mask_list)\n",
    "    \n",
    "    return attention_masks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_avg = int(np.mean([len(sen) for sen in train_text_ids]))\n",
    "print(\"train_text_avg:\", train_text_avg)\n",
    "train_padding_list = padding_truncating(train_text_ids, max_length=train_text_avg)\n",
    "test_padding_list = padding_truncating(test_text_ids, max_length=train_text_avg)\n",
    "\n",
    "\n",
    "train_attention_masks = get_attention_masks(train_padding_list)\n",
    "test_attention_masks = get_attention_masks(test_padding_list)\n",
    "\n",
    "assert len(train_text) == len(train_labels) == len(train_attention_masks) == len(train_padding_list)\n",
    "assert len(test_text) == len(test_labels) == len(test_attention_masks) == len(test_padding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padding_list, validation_padding_list, train_labels, validation_labels, train_attention_masks, validation_attention_masks = train_test_split(train_padding_list, train_labels, train_attention_masks, test_size=0.25)\n",
    "\n",
    "# train_padding_list = train_padding_list[:3]\n",
    "# validation_padding_list = [train_padding_list[-1]]\n",
    "# train_labels = train_labels[:3]\n",
    "# validation_labels = [train_labels[-1]]\n",
    "# train_attention_masks = train_attention_masks[:3]\n",
    "# validation_attention_masks = [train_attention_masks[-1]]\n",
    "\n",
    "assert len(train_labels) == len(train_attention_masks) == len(train_padding_list)\n",
    "assert len(validation_labels) == len(validation_attention_masks) == len(validation_padding_list)\n",
    "assert len(test_labels) == len(test_attention_masks) == len(test_padding_list)\n",
    "\n",
    "print(\"len(train_labels) = {}\\nlen(validation_labels) = {}\\nlen(test_labels) = {}\".format(len(train_labels), len(validation_labels), len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_padding_list)\n",
    "validation_inputs = torch.tensor(validation_padding_list)\n",
    "test_inputs = torch.tensor(test_padding_list)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_attention_masks)\n",
    "validation_masks = torch.tensor(validation_attention_masks)\n",
    "test_masks = torch.tensor(test_attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels = 2, output_attentions = False, output_hidden_states = False)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "print(\"total_steps = {}\".format(total_steps))\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_val = 12345\n",
    "# random.seed(seed_val)\n",
    "# np.random.seed(seed_val)\n",
    "# torch.manual_seed(seed_val)\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')  \n",
    "    t0 = time.time()\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 1 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "    \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad() \n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader) \n",
    "    loss_values.append(avg_train_loss)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad(): \n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "            \n",
    "        logits = outputs[0]         \n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "plt.plot(loss_values, 'b-o')\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    "idx = 0\n",
    "correct = 0\n",
    "for batch in test_dataloader:\n",
    "    print(\"Batch {}\".format(idx + 1))\n",
    "    idx += 1\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "    logits = outputs[0]\n",
    "    pred = np.argmax(logits, axis=1)\n",
    "    correct += (pred == b_labels).sum().item()\n",
    "    print(\"correct = {}\\n\".format(correct))\n",
    "\n",
    "print('DONE.')\n",
    "print(\"Total correct = \", correct)\n",
    "print(\"Test accuracy = {0:.2f}\".format(correct / len(test_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = \"saved models/Pytorch\"\n",
    "\n",
    "if not os.path.exists(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "model.save_pretrained(saved_model_dir)\n",
    "tokenizer.save_pretrained(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = BertForSequenceClassification.from_pretrained(saved_model_dir)       \n",
    "load_tokenizer = BertTokenizer.from_pretrained(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
